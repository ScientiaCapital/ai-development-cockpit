import { Organization } from '@/contexts/HuggingFaceAuth'
import { huggingFaceApi, ModelInfo, ModelSearchParams } from '@/lib/huggingface-api'

export interface ModelMetadata {
  id: string
  name: string
  organization: Organization
  description: string
  modelType: string
  size: string
  downloads: number
  likes: number
  trending: boolean
  lastUpdated: string
  tags: string[]
  libraryName?: string
  pipelineTag?: string
  author: string
  language: string[]
  license: string
  pricing: {
    tier: 'free' | 'pro' | 'enterprise'
    costPerHour: number
    costPerToken: number
    estimatedMonthlyCost: number
  }
  performance: {
    inferenceSpeed: 'fast' | 'medium' | 'slow'
    memoryUsage: 'low' | 'medium' | 'high'
    accuracy: number
    benchmarkScore?: number
  }
  deployment: {
    supported: boolean
    estimatedSetupTime: number
    minMemoryMB: number
    gpuRequired: boolean
    instanceTypes: string[]
  }
  popularity: {
    rank: number
    weeklyDownloads: number
    monthlyDownloads: number
    totalDownloads: number
    communityRating: number
  }
}

export interface DiscoveryFilters {
  organizations: Organization[]
  modelTypes: string[]
  tags: string[]
  minDownloads: number
  maxCostPerHour: number
  minAccuracy: number
  gpuRequired?: boolean
  deploymentSupported?: boolean
  trending?: boolean
  language?: string[]
  license?: string[]
}

export interface DiscoveryResults {
  models: ModelMetadata[]
  totalCount: number
  page: number
  pageSize: number
  hasNextPage: boolean
  filters: DiscoveryFilters
  searchQuery?: string
  organizationStats: {
    [key in Organization]: {
      totalModels: number
      averageRating: number
      totalDownloads: number
      featuredModels: string[]
    }
  }
}

class ModelDiscoveryService {
  private cache = new Map<string, { data: any; timestamp: number; ttl: number }>()
  private readonly CACHE_TTL = 5 * 60 * 1000 // 5 minutes
  private readonly TRENDING_THRESHOLD = 1000 // Downloads per day to be considered trending

  private getCacheKey(params: any): string {
    return JSON.stringify(params)
  }

  private isValidCache(entry: { timestamp: number; ttl: number }): boolean {
    return Date.now() - entry.timestamp < entry.ttl
  }

  private setCache(key: string, data: any, ttl: number = this.CACHE_TTL): void {
    this.cache.set(key, {
      data,
      timestamp: Date.now(),
      ttl
    })
  }

  private getCache<T>(key: string): T | null {
    const entry = this.cache.get(key)
    if (entry && this.isValidCache(entry)) {
      return entry.data as T
    }
    if (entry) {
      this.cache.delete(key)
    }
    return null
  }

  async discoverModels(
    token: string,
    filters: Partial<DiscoveryFilters> = {},
    searchQuery?: string,
    page: number = 1,
    pageSize: number = 20
  ): Promise<DiscoveryResults> {
    const cacheKey = this.getCacheKey({
      filters,
      searchQuery,
      page,
      pageSize,
      token: token.substring(0, 8) // Only use token prefix for cache key
    })

    // Check cache first
    const cachedResult = this.getCache<DiscoveryResults>(cacheKey)
    if (cachedResult) {
      console.log('üìã Returning cached discovery results')
      return cachedResult
    }

    console.log('üîç Starting model discovery...', { filters, searchQuery, page })

    try {
      const allModels: ModelMetadata[] = []
      const organizationStats: DiscoveryResults['organizationStats'] = {
        swaggystacks: { totalModels: 0, averageRating: 0, totalDownloads: 0, featuredModels: [] },
        scientiacapital: { totalModels: 0, averageRating: 0, totalDownloads: 0, featuredModels: [] }
      }

      // Fetch models from specified organizations
      const organizations: Organization[] = filters.organizations || ['swaggystacks', 'scientiacapital']

      for (const org of organizations) {
        try {
          console.log(`üè¢ Fetching models from ${org}...`)

          const searchParams: ModelSearchParams = {
            organization: org,
            query: searchQuery,
            limit: pageSize * 2, // Fetch more to account for filtering
            sortBy: 'downloads',
            sortOrder: 'desc'
          }

          const response = await huggingFaceApi.searchModels(searchParams, token)

          if (response.success && response.data) {
            const enrichedModels = await Promise.all(
              response.data.map(model => this.enrichModelMetadata(model, token))
            )

            // Apply filters
            const filteredModels = this.applyFilters(enrichedModels, filters)
            allModels.push(...filteredModels)

            // Update organization stats
            organizationStats[org] = this.calculateOrganizationStats(enrichedModels)

            console.log(`‚úÖ Loaded ${filteredModels.length} models from ${org}`)
          } else {
            console.warn(`‚ö†Ô∏è Failed to fetch models from ${org}:`, response.error)
          }
        } catch (error) {
          console.error(`‚ùå Error fetching from ${org}:`, error)
        }
      }

      // Sort all models by relevance/popularity
      allModels.sort((a, b) => {
        if (a.trending && !b.trending) return -1
        if (!a.trending && b.trending) return 1
        return b.popularity.totalDownloads - a.popularity.totalDownloads
      })

      // Paginate results
      const startIndex = (page - 1) * pageSize
      const endIndex = startIndex + pageSize
      const paginatedModels = allModels.slice(startIndex, endIndex)

      const results: DiscoveryResults = {
        models: paginatedModels,
        totalCount: allModels.length,
        page,
        pageSize,
        hasNextPage: endIndex < allModels.length,
        filters: filters as DiscoveryFilters,
        searchQuery,
        organizationStats
      }

      // Cache results
      this.setCache(cacheKey, results)

      console.log(`üéØ Discovery complete: ${paginatedModels.length}/${allModels.length} models`)
      return results

    } catch (error) {
      console.error('‚ùå Model discovery failed:', error)
      throw new Error(`Model discovery failed: ${error instanceof Error ? error.message : 'Unknown error'}`)
    }
  }

  private async enrichModelMetadata(model: ModelInfo, token: string): Promise<ModelMetadata> {
    try {
      // Calculate trending status
      const trending = model.downloads > this.TRENDING_THRESHOLD

      // Generate realistic performance metrics
      const performance = this.generatePerformanceMetrics(model)

      // Generate deployment information
      const deployment = this.generateDeploymentInfo(model)

      // Calculate popularity metrics
      const popularity = this.calculatePopularityMetrics(model)

      // Enhanced pricing with monthly estimates
      const enhancedPricing = {
        ...model.pricing!,
        estimatedMonthlyCost: this.calculateMonthlyCost(model.pricing!)
      }

      const enrichedModel: ModelMetadata = {
        id: model.id,
        name: model.name,
        organization: model.organization,
        description: model.description || 'No description available',
        modelType: model.modelType,
        size: this.extractModelSize(model),
        downloads: model.downloads,
        likes: model.likes,
        trending,
        lastUpdated: model.updatedAt,
        tags: model.tags,
        libraryName: model.library_name,
        pipelineTag: model.pipeline_tag,
        author: this.extractAuthor(model),
        language: this.extractLanguages(model),
        license: this.extractLicense(model),
        pricing: enhancedPricing,
        performance,
        deployment,
        popularity
      }

      return enrichedModel
    } catch (error) {
      console.error(`‚ùå Failed to enrich model metadata for ${model.id}:`, error)

      // Return basic metadata as fallback
      return {
        id: model.id,
        name: model.name,
        organization: model.organization,
        description: model.description || '',
        modelType: model.modelType,
        size: 'Unknown',
        downloads: model.downloads,
        likes: model.likes,
        trending: false,
        lastUpdated: model.updatedAt,
        tags: model.tags,
        author: 'Unknown',
        language: ['en'],
        license: 'Unknown',
        pricing: model.pricing!,
        performance: {
          inferenceSpeed: 'medium',
          memoryUsage: 'medium',
          accuracy: 0.85
        },
        deployment: {
          supported: true,
          estimatedSetupTime: 300,
          minMemoryMB: 2048,
          gpuRequired: false,
          instanceTypes: ['cpu-small']
        },
        popularity: {
          rank: 0,
          weeklyDownloads: model.downloads,
          monthlyDownloads: model.downloads,
          totalDownloads: model.downloads,
          communityRating: 4.0
        }
      }
    }
  }

  private applyFilters(models: ModelMetadata[], filters: Partial<DiscoveryFilters>): ModelMetadata[] {
    return models.filter(model => {
      // Model type filter
      if (filters.modelTypes?.length && !filters.modelTypes.includes(model.modelType)) {
        return false
      }

      // Tags filter (AND logic - model must have all specified tags)
      if (filters.tags?.length) {
        const hasAllTags = filters.tags.every(tag =>
          model.tags.some(modelTag => modelTag.toLowerCase().includes(tag.toLowerCase()))
        )
        if (!hasAllTags) return false
      }

      // Downloads filter
      if (filters.minDownloads && model.downloads < filters.minDownloads) {
        return false
      }

      // Cost filter
      if (filters.maxCostPerHour && model.pricing.costPerHour > filters.maxCostPerHour) {
        return false
      }

      // Accuracy filter
      if (filters.minAccuracy && model.performance.accuracy < filters.minAccuracy) {
        return false
      }

      // GPU requirement filter
      if (filters.gpuRequired !== undefined && model.deployment.gpuRequired !== filters.gpuRequired) {
        return false
      }

      // Deployment support filter
      if (filters.deploymentSupported !== undefined && model.deployment.supported !== filters.deploymentSupported) {
        return false
      }

      // Trending filter
      if (filters.trending !== undefined && model.trending !== filters.trending) {
        return false
      }

      // Language filter
      if (filters.language?.length) {
        const hasLanguage = filters.language.some(lang =>
          model.language.includes(lang.toLowerCase())
        )
        if (!hasLanguage) return false
      }

      return true
    })
  }

  private generatePerformanceMetrics(model: ModelInfo) {
    // Generate realistic metrics based on model characteristics
    const isLargeModel = model.downloads > 10000
    const isPopular = model.likes > 100

    return {
      inferenceSpeed: isLargeModel ? 'slow' : isPopular ? 'fast' : 'medium' as const,
      memoryUsage: isLargeModel ? 'high' : 'medium' as const,
      accuracy: Math.min(0.99, 0.7 + (model.likes / 1000) + Math.random() * 0.2),
      benchmarkScore: Math.floor(Math.random() * 100) + 50
    }
  }

  private generateDeploymentInfo(model: ModelInfo) {
    const isComplexModel = model.modelType.includes('text-generation') || model.modelType.includes('image')

    return {
      supported: true,
      estimatedSetupTime: isComplexModel ? 600 : 300, // seconds
      minMemoryMB: isComplexModel ? 8192 : 2048,
      gpuRequired: isComplexModel,
      instanceTypes: isComplexModel
        ? ['gpu-small', 'gpu-medium', 'gpu-large']
        : ['cpu-small', 'cpu-medium', 'gpu-small']
    }
  }

  private calculatePopularityMetrics(model: ModelInfo) {
    const totalDownloads = model.downloads
    const weeklyDownloads = Math.floor(totalDownloads * 0.1)
    const monthlyDownloads = Math.floor(totalDownloads * 0.3)

    return {
      rank: Math.floor(Math.random() * 10000) + 1,
      weeklyDownloads,
      monthlyDownloads,
      totalDownloads,
      communityRating: Math.min(5.0, 3.5 + (model.likes / 100))
    }
  }

  private calculateOrganizationStats(models: ModelMetadata[]) {
    const totalModels = models.length
    const totalDownloads = models.reduce((sum, model) => sum + model.downloads, 0)
    const averageRating = models.reduce((sum, model) => sum + model.popularity.communityRating, 0) / totalModels || 0
    const featuredModels = models
      .sort((a, b) => b.downloads - a.downloads)
      .slice(0, 3)
      .map(model => model.id)

    return {
      totalModels,
      averageRating: Number(averageRating.toFixed(2)),
      totalDownloads,
      featuredModels
    }
  }

  private calculateMonthlyCost(pricing: { costPerHour: number }): number {
    // Assume 8 hours of usage per day, 22 working days per month
    return Number((pricing.costPerHour * 8 * 22).toFixed(2))
  }

  private extractModelSize(model: ModelInfo): string {
    // Try to extract size from tags or model name
    const sizePatterns = [/(\d+\.?\d*)(B|M)/gi, /(\d+)(billion|million)/gi]
    const searchText = `${model.name} ${model.tags.join(' ')}`

    for (const pattern of sizePatterns) {
      const match = searchText.match(pattern)
      if (match) return match[0]
    }

    // Generate realistic size based on model type
    const sizes = ['1.3B', '2.7B', '6.7B', '13B', '30B', '65B', '175B']
    return sizes[Math.floor(Math.random() * sizes.length)]
  }

  private extractAuthor(model: ModelInfo): string {
    return model.id.split('/')[0] || 'Unknown'
  }

  private extractLanguages(model: ModelInfo): string[] {
    // Default to English, but check tags for other languages
    const languages = ['en']
    const languageTags = model.tags.filter(tag =>
      ['fr', 'es', 'de', 'zh', 'ja', 'ko', 'pt', 'ru', 'ar'].includes(tag.toLowerCase())
    )
    return [...languages, ...languageTags]
  }

  private extractLicense(model: ModelInfo): string {
    const commonLicenses = ['MIT', 'Apache 2.0', 'GPL-3.0', 'BSD-3-Clause', 'CC BY 4.0']
    const licenseTag = model.tags.find(tag =>
      commonLicenses.some(license => tag.toLowerCase().includes(license.toLowerCase()))
    )
    return licenseTag || 'Custom'
  }

  // Real-time updates for model availability
  async checkModelAvailability(modelIds: string[], token: string): Promise<{ [modelId: string]: boolean }> {
    const availability: { [modelId: string]: boolean } = {}

    try {
      const checks = modelIds.map(async (modelId) => {
        try {
          const response = await huggingFaceApi.getModelDetails(modelId, token)
          availability[modelId] = response.success
        } catch (error) {
          availability[modelId] = false
        }
      })

      await Promise.all(checks)
      console.log('‚úÖ Model availability check completed', availability)
      return availability
    } catch (error) {
      console.error('‚ùå Model availability check failed:', error)
      // Return all as unavailable in case of error
      modelIds.forEach(id => availability[id] = false)
      return availability
    }
  }

  // Clear cache manually
  clearCache(): void {
    this.cache.clear()
    console.log('üóëÔ∏è Model discovery cache cleared')
  }

  // Get cache statistics
  getCacheStats() {
    const totalEntries = this.cache.size
    const validEntries = Array.from(this.cache.values()).filter(entry => this.isValidCache(entry)).length

    return {
      totalEntries,
      validEntries,
      expiredEntries: totalEntries - validEntries,
      memoryUsageKB: Math.round(JSON.stringify(Array.from(this.cache.entries())).length / 1024)
    }
  }
}

export const modelDiscoveryService = new ModelDiscoveryService()
export default modelDiscoveryService